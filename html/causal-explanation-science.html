<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html lang="en"> <!-- <![endif]-->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Causal Approaches to Scientific Explanation (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Causal Approaches to Scientific Explanation" />
<meta property="citation_author" content="Ross, Lauren" />
<meta property="citation_author" content="Woodward, James" />
<meta property="citation_publication_date" content="2023/03/17" />
<meta name="DC.title" content="Causal Approaches to Scientific Explanation" />
<meta name="DC.creator" content="Ross, Lauren" />
<meta name="DC.creator" content="Woodward, James" />
<meta name="DCTERMS.issued" content="2023-03-17" />
<meta name="DCTERMS.modified" content="2023-03-17" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
                    <li role="menuitem"><a href="../../new.html">What's New</a></li>
                    <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li role="menuitem"><a href="../../published.html">Chronological</a></li>
                    <li role="menuitem"><a href="../../archives/">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
                    <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
                    <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
                    <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
                    <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
                    <li role="menuitem"><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
                    <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
                    <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="../../search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit" aria-label="search"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/causal-explanation-science/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=causal-explanation-science">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Causal Approaches to Scientific Explanation</h1><div id="pubinfo"><em>First published Fri Mar 17, 2023</em></div>

<div id="preamble">

<p>
This entry discusses some accounts of <em>causal</em> explanation
developed after approximately 1990. For a discussion of earlier
accounts of explanation including the deductive-nomological (DN)
model, Wesley Salmon&rsquo;s statistical relevance and causal
mechanical models, and unificationist models, see the general entry on
 <a href="../scientific-explanation/">scientific explanation</a>.
 Recent accounts of non-causal explanation will be discussed in a
separate entry. In addition, a substantial amount of recent discussion
of causation and causal explanation has been conducted within the
framework of causal models. To avoid overlap with the entry on
 <a href="../causal-models/">causal models</a>
 we do not discuss this literature here.</p>

<p>
Our focus in this entry is on the following three accounts &ndash;
Section 1 those that focus on mechanisms and mechanistic explanations,
Section 2 the kairetic account of explanation, and Section 3
interventionist accounts of causal explanation. All of these have as
their target explanations of <em>why</em> or perhaps <em>how</em> some
phenomenon occurs (in contrast to, say, explanations of <em>what</em>
something is, which is generally taken to be non-causal) and they
attempt to capture causal explanations that aim at such explananda.
Section 4 then takes up some recent proposals having to do with how
causal explanations may differ in explanatory depth or goodness.
Section 5 discusses some issues having to do with what is distinctive
about causal (as opposed to non-causal) explanations.</p>

<p>
We also make the following preliminary observation. An account of
causal explanation in science may leave open the possibility that
there are other sorts of explanations of a non-causal variety (it is
just that the account does not claim to capture these, at least
without substantial modifications) or it may, more ambitiously, claim
that all explanations of the why/how variety are, at least in some
extended sense, causal. The kairetic model makes this latter claim, as
do many advocates of mechanistic models. By contrast, interventionist
models, need not deny that there are non-causal explanations, although
the version described below does not attempt to cover such
explanations. Finally, we are very conscious that, for reasons of
space, we omitted many recent discussions of causal explanation from
this entry. We provide brief references to a number of these at the
end of this article (Section 6).</p>
</div> 

<div id="toc"><!--Entry Contents-->
<ul>
	<li><a href="#MechMechExpl">1. Mechanisms and Mechanistic Explanations </a></li>
	<li><a href="#KairAccoExpl">2. The Kairetic Account of Explanation</a></li>
	<li><a href="#InteTheo">3. Interventionist Theories</a></li>
	<li><a href="#ExplDept">4. Explanatory Depth</a></li>
	<li><a href="#NonCausMathExpl">5. Non-causal and Mathematical Explanation</a></li>
	<li><a href="#AddiIssu">6. Additional Issues</a></li>
	<li><a href="#Bib">Bibliography</a></li>
	<li><a href="#Aca">Academic Tools</a></li>
	<li><a href="#Oth">Other Internet Resources</a></li>
	<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr /></div>

<div id="main-text">

<h2 id="MechMechExpl">1. Mechanisms and Mechanistic Explanations</h2>

<p>
Many accounts of causation and explanation assign a central importance
to the notion of mechanism. While discussions of mechanism are present
in the early modern period, with the work of Descartes and others, a
distinct and very influential research program emerged with the
&ldquo;new mechanist&rdquo; approaches of the late twentieth and early
twenty-first century. This section focuses on work in this
tradition.</p>

<p>
Wesley Salmon&rsquo;s causal mechanical (CM) model of explanation
(Salmon 1984) was an influential late twentieth century precursor to
the work on mechanisms that followed. The CM model is described in the
SEP entry on
 <a href="../scientific-explanation/">scientific explanation</a>
 and readers are referred to this for details. For present purposes we
just note the following. First, Salmon&rsquo;s model is proposed as an
alternative to the deductive-nomological (DN) model and the &ldquo;new
mechanist&rdquo; work that follows also rejects the DN model, although
in some cases for reasons somewhat different from Salmon&rsquo;s. Like
the CM model and in contrast to the DN model, the new mechanist
tradition downplays the role of laws in explanation, in part because
(it is thought) there are relatively few laws in the life sciences,
which are the primary domain of application of recent work on
mechanisms. Second, although Salmon provides an account of causal
relationships that are in an obvious sense &ldquo;mechanical&rdquo;,
he focuses virtually entirely on physical examples (like billiard ball
collisions) rather than examples from the life sciences. Third Salmon
presents his model as an &ldquo;ontic&rdquo; account of explanation,
according to which explanations are things or structures in the world
and contrasts this with what he regarded as &ldquo;epistemic&rdquo;
accounts of explanation (including in his view, the DN model) which
instead conceive of explanations as representations of what is in the
world (Salmon 1984). This &ldquo;ontic&rdquo; orientation has been
important in the work of some of the new mechanists, such as Craver
(2007a), but less so for others. Finally, Salmon&rsquo;s model
introduces a distinction between the &ldquo;etiological&rdquo; aspects
of explanation which have to do with tracing the causal history of
some event <em>E</em> and the &ldquo;constitutive&rdquo; aspects which
have to do with &ldquo;the internal causal mechanisms that account for
<em>E</em>&rsquo;s nature&rdquo; (Salmon 1984: 275). This focus on the
role of &ldquo;constitution&rdquo; is retained by a number of the new
mechanists.</p>

<p>
We may think of the &ldquo;new mechanism&rdquo; research program
properly speaking as initiated by writers like Bechtel and Richardson
(1993 [2010]), Glennan (1996, 1997), and Machamer, Darden, and Craver
(2000). Although these writers provide accounts that differ in
 detail,<sup>[<a href="notes.html#note-1" id="ref-1">1</a>]</sup>
 they share common elements: mechanisms are understood as causal
systems, exhibiting a characteristic organization, with multiple
causal factors that work together in a coordinated manner to produce
some effect of interest. Providing a mechanistic explanation involves
explaining an outcome by appealing to the causal mechanism that
produces it. The components of a mechanism stand in causal
relationships but most accounts conceptualize the relationship between
these components and the mechanism itself as a part-whole or
&ldquo;constitutive relationship&rdquo; &ndash; e.g., a human cell is constituted
by various molecules, compounds and organelles, the human visual
system is constituted by various visual processing areas (including
V1&ndash;V5) and an automobile engine may be constituted by pistons,
cylinders, camshaft and carburetor, among other components. Such
part/whole relations are generally conceptualized as non-causal
&ndash; that is, constitution is seen as a non-causal relationship.
Thus, on these accounts, mechanisms are composed of or constituted by
lower-level causal parts that interact together to produce the
higher-level behavior of the (whole) mechanism understood as some
effect of interest. This part-whole picture gives mechanistic
explanation a partially reductive character, in the sense that
higher-level outcomes characterizing the whole mechanism are explained
by the lower-level causes that produce them. In many accounts this is
depicted in nested, hierarchical diagrams describing these relations
between levels of mechanisms (Craver 2007a).</p>

<p>
Although philosophical discussion has often focused on the role of
constitutive relations in mechanisms and how best to understand these,
it is, as noted above, also common to think of mechanism as consisting
of factors or components that stand in causal
(&ldquo;etiological&rdquo;) relations to one another with accompanying
characteristic spatial, temporal or geometrical organization. This
feature of mechanism and mechanistic explanation is emphasized by
Illari and Williamson (2010, 2012) and Woodward (2002, 2013). In
particular, elucidating a mechanism is often understood as involving
the identification of &ldquo;mediating&rdquo; factors that are
&ldquo;between&rdquo; the input to the mechanism and its eventual
output &ndash; &ldquo;between&rdquo; both in the sense of causally
between and in the sense that the operation of these mediating factors
often can be thought of as spatially and temporally between the input
to the mechanism and its output. (The causal structure and the
spatiotemporal structure thus &ldquo;mirror&rdquo; or run parallel to
each other.) Often this information about intermediates can be thought
of as describing the &ldquo;steps&rdquo; by which the mechanism
operates over time. For example, mechanistic explanations of the
action potential will cite the (anatomical) structure of the neural
cell membrane, the relative location and structure of ion channels (in
this membrane), ion types on either side of this membrane, and the
various temporal steps in the opening and closing of ion channels that
generate the action potential. A step-by-step description of this
mechanism cites all of these parts and their interactions from the
beginning of the causal process to the end. In this respect a
description of a mechanism will provide more detail than, say,
directed acyclic graphs which describe causal relations among
variables but do not provide spatio-temporal or geometrical
information.</p>

<p>
A hotly debated issue in the literature on mechanisms concerns the
amount of detail descriptions of mechanisms or mechanistic
explanations need to contain. While some mechanists suggest that
mechanisms (or their descriptions) can be abstract or lacking in
detail (Levy &amp; Bechtel 2012), it is more commonly claimed that
mechanistic explanations must contain significant detail &ndash;
perhaps as much &ldquo;relevant&rdquo; detail as possible or at least
that this should be so for an &ldquo;ideally complete
description&rdquo; of a mechanism (see Craver 2006 and the discussion
in
 <a href="#ExplDept">Section 4</a>).
 Thus, a mere description of an input-output causal relation, even if
correct, lacks sufficient detail to count as a description of a
mechanism. For example, a randomized control trial can support the
claim that drug <em>X</em> causes recovery <em>Y</em>, but this alone
doesn&rsquo;t elucidate the &ldquo;mechanism of action&rdquo; of the
drug. Craver (2007a: 113&ndash;4) goes further, suggesting that even
models that provide substantial information about anatomical
structures and causal intermediaries are deficient <em>qua</em>
mechanistic explanations if they omit detail thought to be relevant.
For example, the original Hodgkin-Huxley (HH) model of the action
potential identified a role for the opening and closing of membrane
channels but did not specify the molecular mechanisms involved in the
opening and closing of those channels. Craver (2006, 2007a, 2008)
takes this to show that the HH model is explanatorily deficient
&ndash; it is a &ldquo;mechanism sketch&rdquo; rather than a fully
satisfactory mechanistic explanation. (This is echoed by Glennan who
states that the monocausal model of disease &ndash; a one cause-one
effect relationship &ndash; is &ldquo;the sketchiest of mechanism
sketches&rdquo; [Glennan 2017: 226].) This &ldquo;the more relevant
detail the better&rdquo; view has in turn been criticized by those who
think that one can sometimes improve the quality of an explanation or
at least make it no worse by omitting detail. For such criticism see,
e.g., Batterman and Rice (2014), Levy (2014), Chirimuuta (2014), Ross
(2015, 2020), etc. and for a response see by Craver and Kaplan
 (2020).<sup>[<a href="notes.html#note-2" id="ref-2">2</a>]</sup></p>
 
<p>
The new mechanists differ among themselves in their views of causation
and their attitudes toward general theories of causation found in the
philosophical literature. Since a mechanism involves components
standing in causal relations, one might think that a satisfactory
treatment of mechanisms should include an account of what is meant by
&ldquo;causal relations&rdquo;. Some mechanists have attempted to
provide such an account. For example, Craver (2007a) appeals to
elements of Woodward&rsquo;s interventionist account of causation in
this connection and for other purposes &ndash; e.g., to provide an
account of constitutive relevance (Craver 2007b). By contrast, Glennan
(1996, 2017) argues that the notion of mechanism is more fundamental
than that of causation and that the former can be used to elucidate
the latter &ndash; roughly, <em>X</em> causes <em>Y</em> when there is
a mechanism connecting <em>X</em> to <em>Y</em>. Of course, for
Glennan&rsquo;s project this requires that mechanism is elucidated in
a way that doesn&rsquo;t appeal to the notion causation. Yet another
view, inspired by Anscombe (1971) and advocated by Machamer, Darden,
and Craver (MDC) (2000), Machamer (2004) and others, eschews any
appeal to general theories of causation and instead describes the
causal features of mechanism in terms of specific causal verbs. For
example, according to MDC, mechanisms involve entities that engage in
&ldquo;activities&rdquo;, with examples of the latter including
&ldquo;attraction&rdquo;, &ldquo;repulsion&rdquo;,
&ldquo;pushing&rdquo; and so on (MDC 2000: 5). It is contended that no
more general account according to which these are instances of some
common genus (causation) is likely to be illuminating. A detailed
evaluation of this claim is beyond the scope of this entry, but we do
wish to note that relatively general theories of causation that go
beyond the cataloging of particular causal activities now flourish not
just in philosophy but in disciplines like computer science and
statistics (Pearl 2000 [2009]; Morgan &amp; Winship, 2014) where they
are often thought to provide scientific and mathematical
illumination.</p>

<p>
Another issue raised by mechanistic accounts concerns their scope. As
we have seen these accounts were originally devised to capture a form
of explanation thought to be widespread in the life sciences. This
aspiration raises several questions. First, are all explanations in
the life sciences &ldquo;mechanistic&rdquo; in the sense captured by
some model of mechanistic explanation? Many new mechanists have
answered this question in the affirmative but there has been
considerable pushback to this claim, with other philosophers claiming
that there are explanations in the life sciences that appeal to
topological or network features (Lange 2013; Huneman 2010; Rathkopf
2018; Kosti&#263; 2020; Ross 2021b), to dynamical systems models (Ross
2015) and to other features deemed &ldquo;non-mechanical&rdquo; as
with computational models in neuroscience (Chirimuuta 2014, 2018).
This debate raises the question of how broadly it is appropriate to
extend the notion of &ldquo;mechanism&rdquo; (Silberstein &amp;
Chemero 2013).</p>

<p>
While the examples above are generally claimed to be non-causal and
non-mechanistic, a further question is whether there are also types of
<em>causal</em> explanation that are non-mechanistic. Answering this
question depends, in part, on how &ldquo;mechanism&rdquo; is defined
and what types of causal structures count as &ldquo;mechanisms&rdquo;.
If mechanisms have the particular features mentioned above &ndash;
part-whole relationships, some significant detail, and mechanical
interactions &ndash; it would seem clear that some causal explanations
are non-mechanistic in the sense that they cite causal systems and
information with different features. For example, causal systems
including pathways, networks, and cascades have been advanced as
important types of causal structures that do not meet standard
mechanism characteristics (Ross 2018, 2021a, forthcoming). Other
examples include complex causal processes that lack machine-like and
fixed causal parts (Dupr&eacute; 2013). This work often questions
whether &ldquo;mechanism&rdquo; fruitfully captures the diversity of
causal structures and causal explanations that are present in
scientific contexts.</p>

<p>
There is an understandable tendency among mechanists to attempt to
extend the scope of their accounts as far as possible but presumably
the point of the original project was that mechanistic explanations
have some <em>distinctive</em> features. Extending the models too far
may lead to loss of sight of these. The problem is compounded by the
fact that &ldquo;mechanism&rdquo; is used in many areas of science as
general term of valorization or approval, as is arguably the case for
talk of the &ldquo;mechanism&rdquo; of natural selection or of
&ldquo;externalizing tendencies&rdquo; as a &ldquo;mechanism&rdquo;
leading to substance abuse. The question is whether these candidates
for mechanisms have enough in common with, say, the mechanism by which
the action potential is produced to warrant the treatment of both by
some common model. Of course, this problem also arises when one
considers the extent to which talk of mechanisms is appropriate
outside of the life sciences. Chemists talk of mechanisms of reaction,
physicists of the Higgs mechanism, and economists of mechanism design,
but again this raises the question of whether an account of
mechanistic explanation should aspire to cover all of these.</p>

<h2 id="KairAccoExpl">2. The Kairetic Account of Explanation</h2>

<p>
This account is developed by Michael Strevens in his <em>Depth</em>
(2008) and in a number of papers (2004, 2013, 2018). Strevens
describes his theory as a &ldquo;two factor&rdquo; account (Strevens
2008: 4). The first factor &ndash; Strevens&rsquo; starting point
&ndash; is the notion of causation or dependence (Strevens calls it
&ldquo;causal influence&rdquo;) that figures in fundamental physics.
Strevens is ecumenical about what this involves. He holds that a
number of different philosophical treatments of causal influence
&ndash; conserved quantity, counterfactual or interventionist &ndash;
will fit his purposes. This notion of causal influence is then used as
input to an account of causal <em>explanation</em> &ndash;
Strevens&rsquo; second factor. A causal explanation of an individual
event <em>e</em> (Strevens&rsquo; starting point) assembles all and
only those causal influences that make a difference to (are
explanatorily relevant to) e. A key idea here is the notion of
<em>causal entailment</em> (Strevens 2008:
 74).<sup>[<a href="notes.html#note-3" id="ref-3">3</a>]</sup>
 A set of premises that causally entail that <em>e</em> occurs
deductively entail this claim and do this in a way that
&ldquo;mirrors&rdquo; the causal influences (ascertained from the
first stage) leading to <em>e</em>. This notion of mirroring is
largely left at an intuitive level but as an illustration a derivation
of an effect from premises describing the cause mirrors the causal
influences leading to the effect while the reverse derivation from
effect to cause does not. However, more than mirroring is required for
causal explanation: The premises in a causal entailment of the sort
just described are subjected to a process (a kind of
&ldquo;abstraction&rdquo;) in which premises that are not necessary
for the entailment of <em>e</em> are removed or replaced with weaker
alternatives that are still sufficient to entail <em>e</em> &ndash;
the result of this being to identify factors which are genuinely
difference-makers or explanatorily relevant to <em>e</em>. The result
is what Strevens calls a &ldquo;stand-alone&rdquo; explanation for
<em>e</em> (Strevens 2008: 70). (Explanatory relevance or
difference-making is thus understood in terms of what, so to speak, is
minimally required for causal entailment, constrained by a
cohesiveness requirement described below, rather than, as in some
other models of explanation, in terms of counterfactuals or
statistical relevance.) As an illustration, if the event <em>e</em> is
the shattering of a window the causal influences on <em>e</em>,
identified from fundamental physics, will be extremely detailed and
will consist of influences that affect fine grained features of
<em>e</em>&rsquo;s occurrence, having to do, e.g., with exactly how
the window shatters. But to the extent that the explanandum is just
whether <em>e</em> occurs most of those details will be irrelevant in
the sense that they will affect only the details of how the shattering
occurs and not whether it occurs at all. Dropping these details will
result in a derivation that still causally entails e. The causal
explanation of <em>e</em> is what remains after all such details have
been dropped and only what is necessary for the causal entailment of
<em>e</em> is retained.</p>

<p>
As Strevens is fully aware, this account faces the following apparent
difficulty. There are a number of different causal scenarios that
realize causes of bottle shatterings &ndash; the impact of rocks but
also, say, sonic booms (cf. Hall 2012). In Strevens&rsquo; view, we
should not countenance causal explanations that disjoin causal models
that describe such highly different realizers, even though weakening
derivations via the inclusion of such disjunctions may preserve causal
entailment. Strevens&rsquo; solution appeals to the notion of
<em>cohesion</em>; when different processes serve as
&ldquo;realizers&rdquo; for the causes of <em>e</em>, these must be
&ldquo;cohesive&rdquo; in the sense that they are &ldquo;causally
contiguous&rdquo; from the point of view of the underlying physics.
Roughly, contiguous causal processes are those that are nearby or
neighbors to one another in a space provided by fundamental
 physics.<sup>[<a href="notes.html#note-4" id="ref-4">4</a>]</sup>
 Sonic booms and rock impacts do not satisfy this cohesiveness
requirement and hence models involving them as disjunctive premises
are excluded. Fundamental physics is thus the arbitrator of whether
upper-level properties with different realizers are sufficiently
similar to satisfy the cohesion requirement. Or at least this is so
for deep &ldquo;stand alone&rdquo; explanations in contrast to those
explanations that are &ldquo;framework&rdquo; dependent (see
below).</p>

<p>
As Strevens sees it, a virtue of his account is that it separates
difficult (&ldquo;metaphysical&rdquo;) questions about the nature of
the causal relationships (at least as these are found in physics which
is Strevens&rsquo; starting point) from issues about causal
explanation, which are the main focus of the kairetic account. It also
follows that most of the causal claims that we consider in common
sense and in science (outside of fundamental physics) are in fact
claims about causal explanation and explanatory relevance as
determined by the kairetic abstraction procedure rather than claims
about causation per se. In effect when one claims that &ldquo;aspirin
causes headache relief&rdquo; one is making a rather complicated
causal explanatory claim about the upshot of the application of the
abstraction procedure to the causal claims that, properly speaking,
are provided by physics. This contrasts with an account in which
causal claims outside of physics are largely univocal with causal
claims (assuming that there are such) within physics.</p>

<p>
We noted above that Strevens imposes a cohesiveness requirement on his
abstraction procedure. This seems to have the consequence that
upper-level causal generalizations that have realizers that are rather
disparate from the point of view of the underlying physics are
defective <em>qua</em> explainers, even though there are many examples
of such generalizations that (rightly or wrongly) are regarded as
explanatory. Strevens addresses this difficulty by introducing the
notion of a <em>framework</em> &ndash; roughly a set of
presuppositions for an explanation. When scientists
&ldquo;framework&rdquo; some aspect of a causal story, they put that
aspect aside (it is presupposed rather an explicit part of the
explanation) and focus on getting the story right for the part that
remains. A common example is to framework details of implementation,
in effect black-boxing the low-level causal explanation of why certain
parts of a system behave in the way they do. The resulting explanation
simply presupposes that these parts do what they do, without
attempting to explain why. Consequently, the black boxes in such
explanations are not subject to the cohesion requirement, because they
are not the locus of explanatory attention . Thus although
explanations appealing to premises with disparate realizers are
defective when considered by themselves as stand-alone explanations,
we may regard such explanations as dependent on a framework with the
framework incorporating information about a presupposed mechanism that
satisfies the coherence
 constraint.<sup>[<a href="notes.html#note-5" id="ref-5">5</a>]</sup>
 When this is the case, the explanation will be acceptable
<em>qua</em> frameworked explanation. Nonetheless in such cases the
explanation should in principle be deepened by making explicit the
information presupposed in the framework.</p>

<p>
Strevens describes his account as &ldquo;descriptive&rdquo; rather
than &ldquo;normative&rdquo; in aspiration. Presumably, however, it is
not intended as a description of the bases on which lay people or
scientists come to accept causal explanations outside of fundamental
physics &ndash; people don&rsquo;t actually go through the abstraction
from fundamental physics process that Strevens describes when they
arrive at or reason about upper-level causal explanations. Instead, as
we understand his account, it is intended to characterize something
like what must be the case from the point of view of fundamental
physics for upper-level causal judgments to be explanatory &ndash; the
explanatory upper-level claims must fit with physics in the right way
as specified in Strevens&rsquo; abstraction procedure and the
accompanying cohesiveness
 constraint.<sup>[<a href="notes.html#note-6" id="ref-6">6</a>]</sup>
 Perhaps then the account is intended to be descriptive in the sense
that the upper-level causal explanations people regard as satisfactory
do in fact satisfy the constraints he describes. In addition, the
account is intended to be descriptive in the sense that it contends
that as a matter of empirical fact people regard their explanations as
committed to various claims about the underlying physics even if these
claims are presently unknown &ndash; e.g., to claims about the
cohesiveness of these
 realizers.<sup>[<a href="notes.html#note-7" id="ref-7">7</a>]</sup>
 At the same time the kairetic account is also normative in the sense
that it judges that explanations that fail to satisfy the constraints
of the abstraction procedure are in some way unsatisfactory &ndash;
thus people are correct to have the commitments described above.</p>

<p>
<em>Depth</em> also contains an interesting treatment of the role of
idealizations in explanation. It is often thought that idealizations
involve the presence of &ldquo;falsehoods&rdquo;, or
&ldquo;distortions&rdquo;. Strevens claims that these
&ldquo;false&rdquo; features involve claims that do not have to do
with difference-makers, in the sense captured by the abstraction
procedure. Thus, according to the kairetic model, it does not matter
if idealizations involve falsehoods or if they omit certain
information since the falsehoods or omitted information do not concern
difference-makers &ndash; their presence thus does not detract from
the resulting explanation. Moreover, we can think of idealizations as
conveying useful information about which factors are not
difference-makers.</p>

<p>
The kairetic account covers a great deal more that we lack the space
to discuss including treatments of what Strevens calls
&ldquo;entanglement&rdquo;, equilibrium explanations, statistical
explanation and much else.</p>

<p>
As is always the case with ambitious theories in philosophy, there
have been a number of criticisms of the kairetic model. Here we
mention just two. First, the kairetic model assumes that all
legitimate explanation is causal or at least that all explanation must
in some way reference or connect with causal information. (A good deal
of the discussion in <em>Depth</em> is concerned to show that
explanations that might seem to be non-causal can nonetheless be
regarded as working by conveying causal information.) This claim that
all explanation is causal is by no means an implausible idea &ndash;
until recently it was widely assumed in the literature on explanation
(Skow 2014). Nonetheless this idea has recently been challenged by a
number of philosophers (Baker 2005; Batterman 2000, 2002, 2010a; Lange
2013, 2016; Lyon 2012; Pincock 2007). Relatedly, the kairetic account
assumes that fundamental physics is &ldquo;causal&rdquo; &ndash;
physics describes causal relations, and indeed lots of causal
relations, enough to generate a large range of upper-level causal
explanations when the abstraction procedure is applied. Some hold
instead that the dependence relations described in physics are either
not causal at all (causation being a notion that applies only to
upper-level or macroscopic relationships) or else that these
dependence relations lack certain important features (such as
asymmetry) that are apparently present in causal explanatory claims
outside of physics (Ney 2009, 2016). These claims about the absence of
causation in physics are controversial but if correct, it follows that
physics does not provide the input that Strevens&rsquo; account
 needs.<sup>[<a href="notes.html#note-8" id="ref-8">8</a>]</sup></p>
 
<p>
A second set of issues concern the kairetic abstraction process. Here
there are several worries. First, the constraints on this process have
struck some as vague since they involve judgments of cohesiveness of
realizers from the point of view of underlying physics. Does physics
or any other science really provide a principled, objective basis for
such judgments? Second, it seems, as suggested above, that upper-level
causal explanations often generalize over realizers that are very
disparate from the point of view of the underlying physics. Potochnik
(2011, 2017) focuses on the example, also discussed by Strevens, of
the Lotka-Volterra (LV) equations which are applied to a large variety
of different organisms that stand in predator/prey relations. Strevens
uses his ideas about frameworks to argue that use of the LV equations
is in some sense justifiable, but it also appears to be a consequence
of his account (and Strevens seems to agree) that explanations
appealing to the LV equations are not very deep, considered as
standalone explanations. But, at least as a descriptive matter,
Potochnik claims, this does not seem to correspond to the judgments or
practices of the scientists using these equations, who seem happy to
use the LV equations despite the fact that they fail to satisfy the
causal contiguity requirement. Potochnik thus challenges this portion
of the descriptive adequacy of Strevens&rsquo; account. Of course, one
might respond that these scientists <em>ought</em> to judge in accord
with Strevens&rsquo; account, but as noted above, this involves taking
the account to have normative implications and not as merely
descriptive.</p>

<p>
A more general form of this issue arises in connection with
&ldquo;universal&rdquo; behavior (Batterman 2002). There are a number
of cases in which physical and biological systems that are very
different from one another in terms of their low-level realizers
exhibit similar or identical upper-level behavior (Batterman 2002;
Batterman &amp; Rice 2014; Ross 2015). As a well-known example,
substances as diverse as ferromagnets and various liquid/gas systems
exhibit similar behavior around their critical points (Batterman 2000,
2002). Renormalization techniques are often thought to explain this
commonality in behavior, but they do so precisely by showing that the
physical details of these systems do not matter for (are irrelevant
to) the aspects of their upper-level behavior of interest. The
features of these systems that are relevant to their behavior have to
do with their dimensionality and symmetry properties among others and
this is revealed by the renormalization group analysis (RGA)
(Batterman 2010b). One interesting question is whether we can think of
that analysis as an instance of Strevens&rsquo; kairetic procedure. On
the one hand the RGA can certainly be viewed as an abstraction
procedure that discards non-difference-making factors. On the other
hand, it is perhaps not so clear the RGA respects the cohesiveness
requirements that Strevens proposes since the upshot is that systems
that are very different at the level of fundamental physics are given
a common explanation. That is, the RGA does not seem to work by
showing (at least in any obvious way) that the systems to which it
applies are contiguous with respect to the underlying
 physics.<sup>[<a href="notes.html#note-9" id="ref-9">9</a>]</sup></p>
 
<p>
Another related issue is this: a number of philosophers claim that the
RGA provides a non-causal explanation (Batterman 2002, 2010a;
Reutlinger 2014). As we have seen, Strevens denies that there are
non-causal explanations in his extended sense of &ldquo;causal&rdquo;
but, in addition, if it is thought the RGA implements Strevens&rsquo;
abstraction procedure, this raises the question of whether (contrary
to Strevens&rsquo; expectations) this procedure can take causal
information as input and yield a non-causal explanation as output. A
contrary view, which may be Strevens&rsquo;, is that as long as the
explanation is the result of applying the kairetic procedure to causal
input, that result must be causal.</p>

<p>
The issue that we have been addressing so far has to do with whether
causal contiguity is a defensible requirement to impose on upper-level
explanations. There is also a related question &ndash; assuming that
the requirement is defensible, how can we tell whether it is
satisfied? The contiguity requirement as well as the whole abstraction
procedure with which it is associated is characterized with reference
to fundamental physics but, as we have noted, users of upper-level
explanations usually have little or no knowledge of how to connect
these with the underlying physics. If Strevens&rsquo; model is to be
applicable to the assessment of upper-level explanations it must be
possible to tell, from the vantage point of those explanations and the
available information that surrounds their use, whether they satisfy
the contiguity and other requirements but without knowing in detail
how they connect to the underlying physics. Strevens clearly thinks
this is possible (as he should, given his views) and in some cases
this seems plausible. For example, it seems fairly plausible, as we
take Strevens to assume, that predator/prey pairs consisting of lions
and zebras are disparate from pairs consisting of spiders and house
flies from the point of view of the underlying physics and thus
constitute heterogeneous realizers of the LV
 equations.<sup>[<a href="notes.html#note-10" id="ref-10">10</a>]</sup>
 On the other hand, in a case of pre-emption in which Billy&rsquo;s
rock shatters a bottle very shortly before Suzy&rsquo;s rock arrives
at the same space, Strevens seems committed to the claim that these
two causal processes are non-contiguous &ndash; indeed he needs this
result to avoid counting Suzy&rsquo;s throw as a cause of the
 shattering<sup>[<a href="notes.html#note-11" id="ref-11">11</a>]</sup>
 (Non-contiguity must hold even if the throws involve rocks with the
same mass and velocity following very similar trajectories, differing
only slightly in their timing.) In other examples, Strevens claims
that airfoils of different flexibility and different materials satisfy
the contiguity constraint, as do different molecular scattering
processes in gases &ndash; apparently this is so even if the latter
are governed by rather different potential functions (as they
sometimes are) (Strevens 2008: 165&ndash;6). The issue here is not
that these judgments are obviously wrong but rather that one would
like to have a more systematic and principled story about the basis on
which they are to be made.</p>

<p>
That said, we think that Strevens has put his finger on an important
issue that deserves more philosophical attention. This is that there
is something explanatorily puzzling or incomplete about a stable
upper-level generalization that appears to have very disparate
realizers: one naturally wants a further explanation of how this comes
about &ndash; one that does not leave it as a kind of unexplained
coincidence that this uniformity of behavior
 occurs.<sup>[<a href="notes.html#note-12" id="ref-12">12</a>]</sup>
 The RGA purports to do this for certain aspects of behavior around
critical points and it does not seem unreasonable to hope for accounts
(perhaps involving some apparatus very different from the RGA) for
other cases. What is less clear is whether such an explanation will
always appeal to causal contiguity at the level of fundamental physics
&ndash; for example in the case of the RGA the relevant factors (and
where causal contiguity appears to obtain) are relatively abstract and
high-level, although certainly &ldquo;physical&rdquo;.</p>

<h2 id="InteTheo">3. Interventionist Theories</h2>

<p>
Interventionist theories are intended both as theories of causation
and of causal explanation. Here we provide only a very quick overview
of the former, referring readers to the entry
 <a href="../causation-mani/">causation and manipulability</a>
 for more detailed discussion of the former and instead focus on
causal explanation. Consider a causal claim (generalization) of the
form</p>

<dl class="sentag tag3em">
<dt>(G)</dt>
<dd>&ldquo;<em>C</em> causes <em>E</em>&rdquo;</dd>
</dl>

<p>
where &ldquo;<em>C</em>&rdquo; and &ldquo;<em>E</em>&rdquo; are
variables &ndash; that is, they refer to properties or quantities that
can take at least two values. Examples are &ldquo;forces cause
accelerations&rdquo; and &ldquo;Smoking causes lung cancer&rdquo;.
According to interventionist accounts (G) is true if and only if there
is a possible intervention <em>I</em> such that if <em>I</em> were to
change the value of <em>C</em>, the value of <em>E</em> or the
probability distribution of <em>E</em> would change (Woodward 2003).
The notion of an intervention is described in more detail in the
 <a href="../causation-mani/">causation and manipulability</a>
 entry, but the basic idea is that this is an unconfounded
experimental manipulation of <em>C</em> that changes <em>E</em>, if at
all, via a route that goes through <em>C</em> and not in any other
way. Counterfactuals that describe would happen if an intervention
were to be performed are called <em>interventionist
counterfactuals</em>. A randomized experiment provides one paradigm of
an intervention.</p>

<p>
Causal explanations can take several different forms within an
interventionist
 framework<sup>[<a href="notes.html#note-13" id="ref-13">13</a>]</sup>
 &ndash; for instance, a causal explanation of some explanandum \(E
=e\) requires:</p>

<dl class="sentag tag3em">
<dt id="ex3.1">(3.1)</dt>
<dd>Specification of a true causal generalization \(E= f(C)\) &ndash;
that is, some set of values of \(C\) is mapped into values of \(E\) by
\(f\) &ndash; meeting the interventionist criterion for causation
described above,</dd>
</dl>

<p>
as well as</p>

<dl class="sentag tag3em">
<dt id="ex3.2">(3.2)</dt>
<dd>One or more initial conditions \(C=c\) (\(C\) being the
independent variable or variables that figure in
 <a href="#ex3.1">(3.1)</a>)
 such that \(E\) is derivable from (3.1) and
 <a href="#ex3.2">(3.2)</a></dd>
 </dl>

<p>
and also meeting the condition</p>

<dl class="sentag tag3em">
<dt id="ex3.3">(3.3)</dt>
<dd>When combined with other initial conditions
 <a href="#ex3.1">(3.1)</a>
 tells us how the value <em>e</em> of <em>E</em> would change under
changes in the initial conditions in specified in
 <a href="#ex3.2">(3.2)</a>.</dd>
 </dl>

<p>
By meeting these conditions (and especially in virtue of satisfying
(3.3)) an explanation answers what Woodward (2003) calls
&ldquo;what-if-things-had-been-different questions&rdquo;
(w-questions) about <em>E</em> &ndash; it tells us how <em>E</em>
would have been different under changes in the values of the
<em>C</em> variable from the value specified in (3.2).</p>

<p>
As an example, consider an explanation of why the strength (E) of the
electrical field created by a long straight wire along which the
charge is uniformly distributed is described by \(E= \lambda/2 \pi r
\epsilon_{o}\) where \(\lambda\) is the charge density and \(r\) is
the distance from the wire. An explanation of this can be constructed
by appealing to Coulomb&rsquo;s law (playing the role of
 <a href="#ex3.1">(3.1)</a>
 above) in conjunction with information about the shape of the wire
and the charge distribution along it
 (<a href="#ex3.2">(3.2)</a>
 above). This information allows for the derivation of \(E= \lambda/2
\pi r \epsilon_{o}\) but it also can be used to provide answers to a
number of other w-questions. For example, Coulomb&rsquo;s law and a
similar modeling strategy can be used to answer questions about what
the field would be if the wire had a different shape (e.g., if twisted
to form a loop) or if it was somehow flattened into a plane or
deformed into a sphere.</p>

<p>
The condition that the explanans answer a range of w-questions is
intended to capture the requirement that the explanans must be
explanatorily relevant to the explanandum. That is, factors having to
do with the charge density and the shape of the conductor are
explanatorily relevant to the field intensity because changes in these
factors would lead to changes in the field intensity. Other factors
such as the color of the conductor are irrelevant and should be
omitted from the explanation because changes in them will not lead to
changes in the field intensity. As an additional illustration,
consider Salmon&rsquo;s (1971a: 34) example of a purported explanation
of (<em>F</em>) a male&rsquo;s failure to get pregnant that appeals to
his taking birth control pills (<em>B</em>). Intuitively (<em>B</em>)
is explanatorily irrelevant to (<em>F</em>). The interventionist model
captures this by observing that <em>B</em> fails to satisfy the
what-if-things-had-been-different requirement with respect to
<em>F</em>: <em>F</em> would not change if <em>B</em> were to change.
(Note the contrast with the rather different way in which the kairetic
model captures explanatory relevance.)</p>

<p>
Another key idea of the interventionist model is the notion of
<em>invariance</em> of a causal generalization (Woodward &amp;
Hitchcock 2003). Consider again a generalization (G) relating \(C\) to
\(E\), \(E= f(C)\). As we have seen, for (G) to describe a causal
relationship at all it must at least be the case that (G) correctly
tells how <em>E</em> would change under at least some interventions on
<em>C</em>. However, causal generalizations can vary according to the
range of interventions over which this is true. It might be that (G)
correctly describes how <em>E</em> would change under some substantial
range <em>R</em> of interventions that set <em>C</em> to different
values or this might instead be true only for some restricted range of
interventions on <em>C</em>. The interventions on <em>C</em> over
which (G) continues to hold are the interventions over which (G) is
<em>invariant.</em> As an illustration consider a type of spring for
which the restoring force <em>F</em> under extensions <em>X</em> is
correctly described by Hooke&rsquo;s law:</p>

<dl class="sentag tag3em">
<dt id="ex3.4">(3.4)</dt>
<dd>\(F=-kX\)</dd>
</dl>

<p>
for some range <em>R</em> of interventions on <em>X</em>. Extending
the spring too much will cause it to break so that its behavior will
no longer be described by Hooke&rsquo;s law.
 <a href="#ex3.4">(3.4)</a>
 is invariant under interventions in <em>R</em> but not so for
interventions outside of <em>R</em>. (3.4) is, intuitively, invariant
only under a somewhat narrow range of interventions. Contrast (3.4)
with the gravitational inverse square law:</p>

<dl class="sentag tag3em">
<dt id="ex3.5">(3.5)</dt>
<dd>\(F= Gm_{1}m_{2}/r^{2}\).</dd>
</dl>

<p>

 <a href="#ex3.5">(3.5)</a>
 is invariant under a rather wide range of interventions that set
\(m_1,\) \(m_2,\) and \(r\) to different values but there are also
values for these variables for which (3.5) fails to hold &ndash; e.g.,
values at which general relativistic effects become important.
Moreover, invariance under interventions is just one variety of
invariance. One may also talk about the invariance of a generalization
under many other sorts of changes &ndash; for example, changes in
background conditions, understood as conditions that are not
explicitly included in the generalization itself. As an illustration,
the causal connection between smoking and lung cancer holds for
subjects with different diets, in different environmental conditions,
with different demographic characteristics and so
 on.<sup>[<a href="notes.html#note-14" id="ref-14">14</a>]</sup>
 However, as explained below, it is invariance under interventions
that is most crucial to evaluating whether an explanation is good or
deep within the interventionist framework.</p>

<p>
Given the account of causal explanation above it follows that for a
generalization to figure in a causal explanation it must be invariant
under at least some interventions. As a general rule a generalization
that is invariant under a wider range of interventions and other
changes will be such that it can be used to answer a wider range of
w-questions. (See
 <a href="#ExplDept">section 4</a>
 below.) In this respect such a generalization might be regarded as
having superior explanatory credentials &ndash; it at least explains
more than generalizations with a narrower range of invariance.
Generalizations that are invariant under a very wide range of
interventions and that have the sort of mathematical formulation that
allows for precise predictions are those that we tend to regard as
laws of nature. Generalizations that have a narrower range of
invariance like Hooke&rsquo;s &ldquo;law&rdquo; capture causal
information but are not plausible candidates for laws of nature. An
interventionist model of form
 <a href="#ex3.1">(3.1&ndash;3.3)</a>
 above thus requires generalizations with some degree of invariance or
relationships that support interventionist counterfactuals, but it
does not require laws. In this respect, like the other models
considered in this entry, it departs from the DN model which does
require laws for successful explanation (see the entry on
 <a href="../scientific-explanation/">scientific explanation</a>).</p>
 
<p>
Turning now to criticisms of the interventionist model, some of these
are also criticisms of interventionist accounts of causation. Several
of these (and particularly the delicate question of what it means for
an intervention to be &ldquo;possible&rdquo;) are addressed if not
resolved in the
 <a href="../causation-mani/">causation and manipulability</a>
 entry.</p>

<p>
Another criticism, not addressed in the above entry, concerns the
&ldquo;truth makers&rdquo; or &ldquo;grounds&rdquo; for the
interventionist counterfactuals that figure in causal explanation.
Many philosophers hold that it is necessary to provide a metaphysical
account of some kind for these. There are a variety of different
proposals &ndash; perhaps interventionist counterfactuals or causal
claims more generally are made true by &ldquo;powers&rdquo; or
&ldquo;dispositions&rdquo;. Perhaps instead such counterfactuals are
grounded in laws of nature, with the latter being understood in terms
of some metaphysical framework, as in the Best Systems Analysis. For
the most part interventionists, have declined to provide truth
conditions of this sort and this has struck some metaphysically minded
philosophers as a serious omission. One response is that while it
certainly makes sense to ask for deeper explanations of why various
interventionist counterfactuals hold, the only explanation that is
needed is an ordinary scientific explanation in terms of some deeper
theory, rather than any kind of distinctively
&ldquo;metaphysical&rdquo; explanation (Woodward 2017b). For example,
one might explain why the interventionist counterfactual &ldquo;if I
were to drop this bottle it will fall to the ground&rdquo; is true by
appealing to Newtonian gravitational theory and
&ldquo;grounding&rdquo; it in this way. (There is also the task of
providing a semantics for interventionist counterfactuals and here
there have been a variety of proposals &ndash; see, e.g., Briggs 2012.
But again, this needn&rsquo;t take the form of providing metaphysical
grounding.) This response raises the question of whether in addition
to ordinary scientific explanations there are metaphysical
explanations (of counterfactuals, laws and so on) that it is the task
of philosophy to provide &ndash; a very large topic that is beyond the
scope of this entry.</p>

<p>
Yet another criticism (pressed by Franklin-Hall 2016 and Weslake 2010)
is that the w-condition implies that explanations at the lowest level
of detail are always superior to explanations employing upper-level
variables &ndash; the argument being that lower-level explanations
will always answer more w-questions than upper-level explanations.
(But see Woodward (2021) for further discussion.)</p>

<h2 id="ExplDept">4. Explanatory Depth</h2>

<p>
Presumably all models of causal explanation (and certainly all of the
models considered above) agree that a causal explanation involves the
assembly of causal information that is relevant to the explanandum of
interest, although different models may disagree about how to
understand causation, causal relevance, and exactly what causal
information is needed for explanation. There is also widespread
agreement (at least among the models considered above) that causal
explanations can differ in how deep or good they are. Capturing what
is involved in variations in depth is thus an important task for a
theory of causal explanation (or for that matter, for any theory of
explanation, causal or non-causal). Unsurprisingly different
treatments of causal explanation provide different accounts of what
explanatory depth consists in. One common idea is that explanations
that drill down (provide information) about lower-level realizing
detail are (to that extent) better &ndash; this is taken to be one
dimension of depth even if not the only one.</p>

<p>
This idea is discussed by Sober (1999) in the context of reduction,
multiple realizability, and causal explanations in biology. Sober
suggests that lower-level details provide objectively superior
explanations compared to higher-level ones and he supports this in
three main ways. First, he suggests that for any explanatory target,
lower-level details can always be included without detracting from an
explanation. The worst offense committed by this extra detail is that
it &ldquo;explains too much,&rdquo; while the same cannot be said for
higher-level detail (Sober 1999: 547). Second, Sober claims that
lower-level details do the &ldquo;work&rdquo; in producing
higher-level phenomena and that this justifies their privilege or
priority in explanations. A similar view is expressed by Waters, who
claims that higher-level detail, while more general, provides
&ldquo;shallow explanations&rdquo; compared to the &ldquo;deeper
accounts&rdquo; provided by lower-level detail (1990: 131). A third
reason is that physics has a kind of &ldquo;causal completeness&rdquo;
that other sciences do not have. It is argued that this causal
completeness provides an objective measure of explanatory strength, in
contrast to the more &ldquo;subjective&rdquo; measures sometimes
invoked in defenses of the explanatory credentials of upper
level-sciences. As Sober (1999: 561) puts it,</p>

<blockquote>

<p>
illumination is to some degree in the eye of the beholder; however,
the sense in which physics can provide complete explanations is
supposed to be perfectly objective.</p>
</blockquote>

<p>
Furthermore,</p>

<blockquote>

<p>
if singular occurrences can be explained by citing their causes, then
the causal completeness of physics [ensures] that physics has a
variety of explanatory completeness that other sciences do not
possess. (1999: 562)</p>
</blockquote>

<p>
Cases where some type-level effect (e.g., a disease) has a shared
causal etiology at higher-levels, but where this etiology is
multiply-realized at lower ones present challenges for such views
(Ross 2020). In Sober&rsquo;s example, &ldquo;smoking causes lung
cancer&rdquo; is a higher-level (macro) causal relationship. He
suggests that lower-level realizers of smoking (distinct carcinogens)
provide deeper explanations of this outcome. One problem with this
claim is that any single lower-level carcinogen only &ldquo;makes a
difference to&rdquo; and explains a narrow subset of all cases of the
disease. By contrast, the higher-level causal factor
&ldquo;smoking&rdquo; makes a difference to all (or most) cases
of this disease. This is reflected in the fact that biomedical
researchers and nonexperts appeal to smoking as the cause of lung
cancer and explicitly target smoking cessation in efforts to control
and prevent this disease. This suggests that there can be drawbacks to
including too much lower-level detail.</p>

<p>
The kairetic theory also incorporates, in some respects, the idea that
explanatory depth is connected to tracking lower-level detail. This is
reflected in the requirement that deeper explanations are those that
are cohesive with respect to fundamental physics &ndash; at the very
least we will be in a better position to see that this requirement is
satisfied when there is supporting information about low-level
 realizers.<sup>[<a href="notes.html#note-15" id="ref-15">15</a>]</sup>
 On the other hand, as we have seen, the kairetic abstraction
procedure taken in itself pushes away from the inclusion of specific
lower-level detail in the direction of greater generality which, in
some form or other, is also regarded by most as a desirable feature in
explanations, the result being a trade-off between these two
desiderata. The role of lower-level detail is somewhat different in
mechanistic models since in typical formulations generality per se is
not given independent weight, and depth is associated with the
provision of more rather than less relevant detail. Of course a great
deal depends on what is meant by &ldquo;relevant detail&rdquo;. As
noted above, this issue is taken up by Craver in several papers,
including most recently, Craver and Kaplan (2020) who discuss what
they call &ldquo;norms of completeness&rdquo; for mechanistic
explanations, the idea being that there needs to be some
&ldquo;stopping point&rdquo; at which a mechanistic explanation is
complete in the sense that no further detail needs to be provided.
Clearly, whatever &ldquo;relevant detail&rdquo; in this connection
means it cannot mean all factors any variation in which would make a
difference to some feature of the phenomenon <em>P</em> which is the
explanatory target. After all, in a molecular level explanation of
some <em>P</em>, variations at the quantum mechanical level &ndash;
say in the potential functions governing the behavior of individual
atoms will often make some difference to <em>P</em>, thus requiring
(on this understanding of relevance) the addition of this information.
Typically, however, such an explanation is taken by mechanists to be
complete just at the molecular level &ndash; no need to drill down
further. Similarly, from a mechanistic point of view an explanation
<em>T</em> of the behavior of a gas in terms of thermodynamic
variables like pressure and temperature is presumably less than fully
adequate since the gas laws are regarded by some if not most
mechanists as merely &ldquo;phenomenological&rdquo; and not as
describing a mechanism. A statistical mechanical explanation (SM) of
the behavior of the gas is better <em>qua</em> mechanistic explanation
but ordinarily such explanations don&rsquo;t advert to, say, the
details of the potentials (DP) governing molecular interactions, even
though variations in these would make some difference to some aspects
of the behavior of the gas. The problem is thus to describe a norm of
completeness that allows one to say that SM is superior to <em>T</em>
without requiring DP rather than SM. Craver and Kaplan&rsquo;s
discussion (2020) is complex and we will not try to summarize it
further here except to say that it does try to find this happy medium
of capturing how a norm of completeness can be met, despite its being
legitimate to omit some detail.</p>

<p>
A closely related issue is this: fine-grained details can be relevant
to an explanandum in the sense that variations in those details may
make a difference to the explanandum but it can also be the case that
those details sometimes can be &ldquo;screened off&rdquo; from or
rendered conditionally irrelevant to this explanandum (or
approximately so) by other, more coarse grained variables that provide
less detail, as described in Woodward 2021. For example, thermodynamic
variables can approximately screen off statistical mechanical
variables from one another. In such a case is it legitimate to omit
(do norms about completeness permit omitting) the more fine-grained
details as long as the more coarse-grained but screening off detail is
included?</p>

<p>
Interventionist accounts, at least in the form described by Woodward
(2003), Hitchcock and Woodward (2003) offer a somewhat different
treatment of explanatory depth. Some candidate explanations will
answer no w-questions and thus fail to be explanatory at all. Above
this threshold explanations may differ in degree of goodness or depth,
depending on the extent to which they provide more rather than less
information relevant to answering w-questions about the explanandum
&ndash; and thus more information about what the explanandum depends
on. For example, an explanation of the behavior of a body falling near
the earth&rsquo;s surface in terms of Galileo&rsquo;s law \(v=gt\) is
less deep than an explanation in terms of the Newtonian law of
gravitation since the latter makes explicit how the rate of fall
depends on the mass of the earth and the distance of the body above
the earth&rsquo;s surface. That is, the Newtonian explanation provides
answers to questions about how the velocity of the fall would have
been different if the mass of the earth had been different, if the
body was falling some substantial distance away from the earth&rsquo;s
surface and so on, thus answering more w-questions than the
explanation appealing to Galileo&rsquo;s law.</p>

<p>
This account associates generality with explanatory depth but this
connection holds only for a particular kind of generality. Consider
the conjunction of Galileo&rsquo;s law and Boyle&rsquo;s law. In one
obvious sense, this conjunction is more general than either
Galileo&rsquo;s law or Boyle&rsquo;s law taken alone &ndash; more
systems will satisfy either the antecedent of Galileo&rsquo;s law or
the antecedent of Boyle&rsquo;s law than one of these generalizations
alone. On the other hand, given an explanandum having to do with the
pressure <em>P</em> exerted by a particular gas, the conjunctive law
will tell us no more about what <em>P</em> depends on than
Boyle&rsquo;s law by itself does. In other words, the addition of
Galileo&rsquo;s law does not allow us to answer any additional
w-questions about the pressure than are answered by Boyle&rsquo;s law
alone. For this reason, this version of interventionism judges that
the conjunctive law does not provide a deeper explanation of
<em>P</em> than Boyle&rsquo;s law despite the conjunctive law being in
one sense more general (Hitchcock &amp; Woodward 2003).</p>

<p>
To develop this idea in a bit more detail, let us say that the
<em>scope</em> of a generalization has to do with the number of
different systems or kinds of systems to which the generalization
applies (in the sense that the systems satisfy the antecedent and
consequents of the generalization). Then the interventionist analysis
claims that greater scope per se does not contribute to explanatory
depth. The conjunction of Galileo&rsquo;s and Boyle&rsquo;s law has
greater scope than either law alone, but it does not provide deeper
explanations.</p>

<p>
As another, perhaps more controversial, illustration consider a set of
generalizations N1 that successfully explain (by interventionist
criteria) the behavior of a kind of neural circuit found only in a
certain kind <em>K</em> of animal. Would the explanatory credentials
of N1 or the depth of the explanations it provides be improved if this
kind of neural circuit was instead found in many different kinds of
animals or if N1 had many more instances? According to the
interventionist treatment of depth under consideration, the answer to
this question is &ldquo;no&rdquo; (Woodward 2003: 367). Such an
extension of the application of N1 is a mere increase in scope.
Learning that N1 applies to other kinds of animals does not tell us
anything more about what the behavior of the original circuit depends
on than if N1 applied just to a single kind of animal.</p>

<p>
It is interesting that philosophical discussions of the explanatory
credentials of various generalizations often assume (perhaps tacitly)
that greater scope (or even greater potential scope in the sense that
there are possible &ndash; perhaps merely metaphysically possible
&ndash; but not actual systems to which the generalization would
apply) per se contributes to explanatory goodness. For example, Fodor
and many others argue for the explanatory value of folk psychology on
the grounds that its generalizations apply not just to humans but
would apply to other systems with the appropriate structure were these
to exist (perhaps certain AI systems, Martians if appropriately
similar to humans etc.) (Fodor 1981: 8&ndash;9). The interventionist
treatment of depth denies there is any reason to think the explanatory
value of folk psychology would be better in the circumstances imagined
above than if it applied only to humans. As another illustration,
Weslake (2010) argues that upper-level generalizations can provide
better or deeper explanations of the same explananda than lower-level
generalizations if there are physically impossible [but metaphysically
possible] systems to which the upper-level explanation applies but to
which the lower-level explanation does not (2010: 287), the reason
being that in such cases the upper- level explanation is more general
in the sense of applying to a wider variety of systems. Suppose for
example, that for some systems governed by the laws of thermodynamics,
the underlying micro theory is Newtonian mechanics and for other
&ldquo;possible&rdquo; or actual systems governed by the same
thermodynamic laws, the correct underlying micro-theory is quite
different. Then, according to Weslake, thermodynamics provides a
deeper explanation than the either of the two micro-theories. This is
also an argument that identifies greater depth with greater scope. The
underlying intuition about depth here is, so to speak, the opposite of
Strevens&rsquo; since he would presumably draw the conclusion that in
this scenario the generalizations of thermodynamics would lack causal
cohesion if the different realizing microsystems were actual.</p>

<p>
This section has focused on recent discussion of the roles played by
the provision of more underlying detail, and generality (in several
interpretations of that notion) in assessments of the depth of causal
explanation. It is arguable that there are a number of other
dimensions of depth that we do not discuss &ndash; readers are
referred to Glymour (1980), Wigner (1967), Woodward (2010), Deutsch
(2011) among many others.</p>

<h2 id="NonCausMathExpl">5. Non-causal and Mathematical Explanation</h2>

<p>
We noted above that there has been considerable recent interest in the
question of whether there are non-causal explanations (of the
&ldquo;why&rdquo; variety) or whether instead all explanations are
causal. Although this entry does not discuss non-causal explanations
in detail, this issue raises the question of whether there is anything
general that might be said about what makes an explanation
&ldquo;causal&rdquo; as opposed to &ldquo;non-causal&rdquo;. In what
follows we review some proposals about the causal/non-causal contrast,
including ideas that abstract somewhat from the details of the
theories described in previous sections.</p>

<p>
We will follow the philosophical literature on this topic by focusing
on candidate explanations that target empirical explananda within
empirical science but (it is claimed) explain these non-causally.
These contrast with explanations within mathematics, as when some
mathematical proofs are regarded as explanatory (of mathematical
facts). Accounts of non-causal explanation in empirical science
typically focus on explanatory factors that seem
&ldquo;mathematical&rdquo;, that abstract from lower-level causal
details, and/or that are related to the explanatory target via
dependency relations that are (in some sense) non-empirical, even
though the explanatory target appears to be an empirical claim. A
common suggestion is that explanations exhibiting one or more of these
features, qualify as non-causal. Purported examples include appeals to
mathematical facts to explain various traits in biological systems,
such as the prime-number life cycles of cicadas, the hexagonal-shape
of the bee&rsquo;s honeycomb, and the fact that seeds on a sunflower
head are described by the golden angle (Baker 2005; Lyon &amp; Colyvan
2008; Lyon 2012). An additional illustration is Lange&rsquo;s claim
(e.g., 2013: 488) that one can explain why 23 strawberries cannot be
evenly divided among three children by appealing to the mathematical
fact that 23 is not evenly divisible by three. It is claimed that in
these cases, explaining the outcome of interest requires appealing to
mathematical relationships, which are distinct from causal
relationships, in the sense that the former are non-contingent and
part of some mathematical theory (e.g., arithmetic, geometry, graph
theory, calculus) or a consequence of some mathematical axiom
system.</p>

<p>
A closely related idea is that in addition to appealing to
mathematical relationships, non-causal explanations abstract from
lower-level detail, with the implication that although these details
may be causal, they are unnecessary for the explanation which is
consequently taken to be non-causal. The question of whether it is
possible to traverse each bridge in the city of K&ouml;nigsberg
exactly once (hereafter just &ldquo;traverse&rdquo;) is a
much-discussed example. Euler provided a mathematical proof that
whether such traversability is possible depends on higher-level
topological or graph-theoretical properties concerning the
connectivity of the bridges, as opposed to any lower-level causal
details of the system (Euler 1736 [1956]; Pincock 2012). This
explanatory pattern is similar to other topological or network
explanations in the literature, which explain despite abstracting from
lower-level causal detail (Huneman 2012; Kostic 2020; Ross 2021b).
Other candidates for non-causal explanations are minimal model
explanations, in which the removal of at least some or perhaps all
causal detail is used to explain why systems which differ
microphysically all exhibit the same behavior in some respects
(Batterman 2002; Chirimuuta 2014; Ross 2015; and the entry on
 <a href="../models-science/">models in science</a>).</p>
 
<p>
Still other accounts (not necessarily inconsistent with those
described above) attempt to characterize some non-causal explanations
in terms of the absence of other features (besides those described
above). Woodward (2018) discusses two types of cases.</p>

<dl class="sentag tag3em">
<dt id="ex5.1">(5.1)</dt>
<dd>Cases in which the factors cited in the explanans are not possible
targets of physical interventions, although we can still ask what
would be the case if those factors were different.</dd>
<dt id="ex5.2">(5.2)</dt>
<dd>Cases in which, although the factors in the explanans are possible
targets of interventions, the dependency relation between explanans
and explanandum is &ldquo;mathematical&rdquo; rather than
contingent.</dd>
</dl>

<p>
An example of
 <a href="#ex5.1">(5.1)</a>
 is a purported explanation relating the possibility of stable
planetary orbits to the dimensionality of space &ndash; given natural
assumptions, stable orbits are possible in a three-dimensional space
but not possible in a space of dimensionality greater than three, so
that the possibility of stable orbits in this sense seems to depend on
the dimensionality of space. (For discussion see Ehrenfest 1917;
B&uuml;chel 1963 [1969]; Callendar 2005). Assuming it is not possible
to intervene to change the dimensionality of space, this explanation
(if that is what it is) is treated as non-causal within an
interventionist framework because of this impossibility. In other
words, the distinction between explanations that appeal to factors
that are targets of possible interventions and those that appeal to
factors that are not targets of possible interventions is taken to
mark one dividing line between causal and non-causal explanations.</p>

<p>
In the second set of cases
 <a href="#ex5.2">(5.2)</a>,
 there <em>are</em> factors cited in the explanans that can be changed
under interventions but the relationship between this property and the
explanandum is non-contingent and &ldquo;mathematical&rdquo;. For
example, it is certainly possible to intervene to change the
configuration of bridges in K&ouml;nigsberg and in this way to change
their traversability but the relation between the bridge configuration
and their traversability is, as we have seen, non-contingent. Many of
the examples mentioned earlier &ndash; the cicada, honeybee, and
sunflower cases &ndash; are similar. In these cases, the
non-contingent character of the dependency relation between explanans
and explanandum is claimed to mark off these explanations as
non-causal.</p>

<p>
A feature of many of the candidates for non-causal explanation
discussed above (and arguably another consideration that distinguishes
causal from non-causal explanations) is that the non-causal
explanations often seem to explain why some outcome is
<em>possible</em> or <em>impossible</em> (e.g., why stable orbits are
possible or impossible in spaces of different dimensions, why it is
possible or not to traverse various configurations of bridges). By
contrast it seems characteristic of causal explanations that they are
concerned with a range of outcomes all of which are taken to be
possible and instead explain why one such outcome in contrast to an
alternative is realized (why an electric field has a certain strength
rather than some alternative strength.)</p>

<p>
While many have taken the above examples to represent clear cases of
non-causal, mathematical explanation, others have argued that these
explanations remain causal through-and-through. One example of this
expansive position about causal explanation is Strevens (2018).
According to Strevens, the K&ouml;nigsberg and other examples are
cases in which mathematics plays a merely representational role, for
example the role of representing difference-makers that dictate the
movement of causal processes in the world. Strevens refers to these as
&ldquo;non-tracking&rdquo; explanations, which identify limitations on
causal processes that can explain their final outcome, but not the
exact path taken to them (Strevens 2018: 112). For Strevens the
topological structure represented in the K&ouml;nigsberg&rsquo;s case
captures information about causal structure or the web of causal
influence &ndash; in this way the information relevant to the
explanation, although abstract, is claimed to be causal. While this
argument is suggestive, one open question is how the kairetic account
can capture the fact that some of these cases involve explanations of
impossibilities, where the source of the impossibility is not
obviously &ldquo;structural&rdquo; (Lange 2013, 2016). For example,
the impossibility of evenly dividing 23 by 3 does not appear to be a
consequence of the way in which a structure influences some causal
 process.<sup>[<a href="notes.html#note-16" id="ref-16">16</a>]</sup></p>
 
<p>
In addition to the examples and considerations just described, the
philosophical literature contains many other proposed contrasts
between causal and non-causal explanations, with accompanying claims
about how to classify particular cases. For example, Sober (1983)
claims that &ldquo;equilibrium explanations&rdquo; are non-causal.
These are explanations in which an outcome is explained by showing
that, because it is an equilibrium (or better, a unique equilibrium) ,
any one of a large number of different more specific processes would
have led to that outcome. As an illustration, for sexually reproducing
populations meeting certain additional conditions (see below), natural
selection will produce an equilibrium in which there are equal numbers
of males and females, although the detailed paths by which this
outcome is produced (which conception events lead to males or females)
will vary on different occasions. The underlying intuition here is
that causal explanations are those that track specific trajectories or
concrete processes, while equilibrium explanations do not do this. By
contrast the kairetic theory treats at least some equilibrium
explanations as causal in an extended sense (Strevens 2008: 267).
Interventionist accounts at least in form described in Woodward (2003)
also take equilibrium explanations to be causal to the extent that
information is provided about what the equilibrium itself depends on.
(That is, the interventionist framework takes the explanandum to be
why this equilibrium rather than some alternative equilibrium
obtains.) For example, the sex ratio equilibrium depends on such
factors as the amount of parental investment required to produce each
sex. Differences in required investment can lead to equilibria in
which there are unequal numbers of males and females. On
interventionist accounts, parental investment is thus among the causes
of the sex ratio because it makes a difference for which equilibrium
is realized. Interventionist accounts are able to reach this
conclusion because they treat relatively &ldquo;abstract&rdquo;
factors like parental investment as causes as long as interventions on
these are systematically associated with associated with changes in
outcomes. Thus, in contrast to some of the accounts described above,
interventionism does not regard the abstractness per se of an
explanatory factor as a bar to interpreting it as causal.</p>

<p>
There has also been considerable discussion of whether computational
explanations of the sort found in cognitive psychology and cognitive
neuroscience that relate inputs to outputs via computations are causal
or mechanistic. Many advocates (Piccinini 2006; Piccinini &amp; Craver
2011) of mechanistic models of explanation have regarded such
explanations as at best mechanism sketches, since they say little or
nothing about realizing (e.g., neurobiological) detail. Since these
writers tend to treat &ldquo;mechanistic explanation&rdquo;,
&ldquo;causal explanation&rdquo; and even &ldquo;explanation&rdquo; as
co-extensional, at least in the biomedical sciences, they seem to
leave no room for a notion of non-causal explanation. By contrast
computational explanations count as causal by interventionist lights
as long as they correctly describe how outputs vary under
interventions on inputs (Rescorla 2014). But other analyses of
computational models suggest that they are similar to non-causal forms
of explanation (Chirimuuta 2014, 2018).</p>

<h2 id="AddiIssu">6. Additional Issues</h2>

<p>
Besides the authors discussed above, there is a great deal of
additional recent work related to causal explanation that we lack the
space to discuss. For additional work on the role of abstraction and
idealization in causal explanation (and whether the presence of
various sorts of abstraction and idealization in an explanation
implies that it is non-causal) see Janssen and Saatsi (2019),
Reutlinger and Andersen (2016), Blanchard (2020), Rice (2021), and
Pincock (2022). Another set of issues that has received a great deal
of recent attention concerns causal explanation in contexts in which
different &ldquo;levels&rdquo; are present (Craver &amp; Bechtel 2007;
Baumgartner 2010; Woodward 2020) This literature addresses questions
of the following sort. Can there be &ldquo;upper-level&rdquo;
causation at all or does all causal action occur at some lower,
microphysical level, with upper-level variables being casually inert?
Can there be &ldquo;cross-level&rdquo; causation &ndash; e.g.,
&ldquo;downward&rdquo; causation from upper to lower levels? Finally,
in addition to the work on explanatory depth discussed in
 <a href="#ExplDept">Section 4</a>,
 there has been a substantial amount of recent work on distinctions
among different sorts of causal claims (Woodward 2010; Ross 2021a;
Ross &amp; Woodward 2022) and on what makes some causes more
explanatorily significant than others (e.g., Potochnik 2015).</p>
</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>

<ul class="hanging">

<li>Andersen, Holly, 2014a, &ldquo;A Field Guide to Mechanisms: Part
I: A Field Guide to Mechanisms I&rdquo;, <em>Philosophy Compass</em>,
9(4): 274&ndash;283. doi:10.1111/phc3.12119</li>

<li>&ndash;&ndash;&ndash;, 2014b, &ldquo;A Field Guide to Mechanisms:
Part II: A Field Guide to Mechanisms II&rdquo;, <em>Philosophy
Compass</em>, 9(4): 284&ndash;293. doi:10.1111/phc3.12118</li>

<li>Anscombe, G. E. M., 1971, <em>Causality and Determination: An
Inaugural Lecture</em>, Cambridge: Cambridge University Press.
Reprinted in <em>Causation</em>, Ernest Sosa and Michael Tooley
(eds.), Oxford/New York: Oxford University Press, 1993,
88&ndash;104.</li>

<li>Baker, Alan, 2005, &ldquo;Are There Genuine Mathematical
Explanations of Physical Phenomena?&rdquo;, <em>Mind</em>, 114(454):
223&ndash;238. doi:10.1093/mind/fzi223</li>

<li>Batterman, Robert W., 2000, &ldquo;Multiple Realizability and
Universality&rdquo;, <em>The British Journal for the Philosophy of
Science</em>, 51(1): 115&ndash;145. doi:10.1093/bjps/51.1.115</li>

<li>&ndash;&ndash;&ndash;, 2002, <em>The Devil in the Details:
Asymptotic Reasoning in Explanation, Reduction, and Emergence</em>,
(Oxford Studies in Philosophy of Science), Oxford/New York: Oxford
University Press. doi:10.1093/0195146476.001.0001</li>

<li>&ndash;&ndash;&ndash;, 2010a, &ldquo;On the Explanatory Role of
Mathematics in Empirical Science&rdquo;, <em>The British Journal for
the Philosophy of Science</em>, 61(1): 1&ndash;25.
doi:10.1093/bjps/axp018</li>

<li>&ndash;&ndash;&ndash;, 2010b, &ldquo;Reduction and
Renormalization&rdquo;, in <em>Time, Chance, and Reduction</em>,
Gerhard Ernst and Andreas H&uuml;ttemann (eds.), Cambridge/New York:
Cambridge University Press, 159&ndash;179.
doi:10.1017/CBO9780511770777.009</li>

<li>&ndash;&ndash;&ndash;, 2021, <em>The Middle Way: A Non-Fundamental
Approach to Many-Body Physics</em>, New York: Oxford University Press.
doi:10.1093/oso/9780197568613.001.0001</li>

<li>Batterman, Robert W. and Collin C. Rice, 2014, &ldquo;Minimal
Model Explanations&rdquo;, <em>Philosophy of Science</em>, 81(3):
349&ndash;376. doi:10.1086/676677</li>

<li>Baumgartner, Michael, 2010, &ldquo;Interventionism and
Epiphenomenalism&rdquo;, <em>Canadian Journal of Philosophy</em>,
40(3): 359&ndash;383. doi:10.1080/00455091.2010.10716727</li>

<li>Bechtel, William and Robert C. Richardson, 1993 [2010],
<em>Discovering Complexity: Decomposition and Localization as
Strategies in Scientific Research</em>, Princeton, NJ: Princeton
University Press. Second edition, Cambridge, MA: The MIT Press,
2010.</li>

<li>Blanchard, Thomas, 2020, &ldquo;Explanatory Abstraction and the
Goldilocks Problem: Interventionism Gets Things Just Right&rdquo;,
<em>The British Journal for the Philosophy of Science</em>, 71(2):
633&ndash;663. doi:10.1093/bjps/axy030</li>

<li>Briggs, Rachael, 2012, &ldquo;Interventionist
Counterfactuals&rdquo;, <em>Philosophical Studies</em>, 160(1):
139&ndash;166. doi:10.1007/s11098-012-9908-5</li>

<li>B&uuml;chel, W., 1963 [1969], &ldquo;Warum hat unser Raum gerade
drei Dimensionen?&rdquo;, <em>Physik Journal</em>, 19(12):
547&ndash;549. Translated and adapted as &ldquo;Why Is Space
Three-Dimensional?&rdquo;, Ira. M. Freeman (trans./adapter),
<em>American Journal of Physics</em>, 37(12): 1222&ndash;1224.
doi:10.1002/phbl.19630191204 (de) doi:10.1119/1.1975283 (en)</li>

<li>Callender, Craig, 2005, &ldquo;Answers in Search of a Question:
&lsquo;Proofs&rsquo; of the Tri-Dimensionality of Space&rdquo;,
<em>Studies in History and Philosophy of Science Part B: Studies in
History and Philosophy of Modern Physics</em>, 36(1): 113&ndash;136.
doi:10.1016/j.shpsb.2004.09.002</li>

<li>Chirimuuta, M., 2014, &ldquo;Minimal Models and Canonical Neural
Computations: The Distinctness of Computational Explanation in
Neuroscience&rdquo;, <em>Synthese</em>, 191(2): 127&ndash;153.
doi:10.1007/s11229-013-0369-y</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;Explanation in Computational
Neuroscience: Causal and Non-Causal&rdquo;, <em>The British Journal
for the Philosophy of Science</em>, 69(3): 849&ndash;880.
doi:10.1093/bjps/axw034</li>

<li>Craver, Carl F., 2006, &ldquo;When Mechanistic Models
Explain&rdquo;, <em>Synthese</em>, 153(3): 355&ndash;376.
doi:10.1007/s11229-006-9097-x</li>

<li>&ndash;&ndash;&ndash;, 2007a, <em>Explaining the Brain: Mechanisms
and the Mosaic Unity of Neuroscience</em>, Oxford: Clarendon Press.
doi:10.1093/acprof:oso/9780199299317.001.0001</li>

<li>&ndash;&ndash;&ndash;, 2007b, &ldquo;Constitutive Explanatory
Relevance&rdquo;:, <em>Journal of Philosophical Research</em>, 32:
3&ndash;20. doi:10.5840/jpr20073241</li>

<li>&ndash;&ndash;&ndash;, 2008, &ldquo;Physical Law and Mechanistic
Explanation in the Hodgkin and Huxley Model of the Action
Potential&rdquo;, <em>Philosophy of Science</em>, 75(5):
1022&ndash;1033. doi:10.1086/594543</li>

<li>Craver, Carl F., and Bechtel, William, 2007, &ldquo;Top-down
Causation Without Top-down Causes&rdquo;&nbsp;<em>Biology &amp;
Philosophy</em>, 22: 547&ndash;563. doi:10.1007/s10539-006-9028-8</li>

<li>Craver, Carl F. and David M. Kaplan, 2020, &ldquo;Are More Details
Better? On the Norms of Completeness for Mechanistic
Explanations&rdquo;, <em>The British Journal for the Philosophy of
Science</em>, 71(1): 287&ndash;319. doi:10.1093/bjps/axy015</li>

<li>Deutsch, David, 2011, <em>The Beginning of Infinity: Explanations
That Transform the World</em>, New York: Viking.</li>

<li>Dupr&eacute;, John, 2013, &ldquo;Living Causes&rdquo;,
<em>Aristotelian Society Supplementary Volume</em>, 87: 19&ndash;37.
doi:10.1111/j.1467-8349.2013.00218.x</li>

<li>Ehrenfest, Paul, 1917, &ldquo;In What Way Does It Become Manifest
in the Fundamental Laws of Physics that Space Has Three
Dimensions?&rdquo;, <em>KNAW, Proceedings</em>, 20(2): 200&ndash;209.
 [<a href="https://dwc.knaw.nl/DL/publications/PU00012213.pdf" target="other">Ehrenfest 1917 available online</a>]</li>
 
<li>Euler, Leonhard, 1736 [1956], &ldquo;Solutio problematis ad
geometriam situs pertinentis&rdquo;, <em>Commentarii Academiae
scientiarum imperialis Petropolitanae</em>, 8: 128&ndash;140.
Translated as &ldquo;The Seven Bridges of K&ouml;nigsberg&rdquo;, in
<em>The World of Mathematics: A Small Library of the Literature of
Mathematics from A&#699;h-Mos&eacute; the Scribe to Albert
Einstein</em>, 4 volumes, by James R. Newman, New York: Simon and
Schuster, 1:573&ndash;580.</li>

<li>Fodor, Jerry A., 1981, <em>Representations: Philosophical Essays
on the Foundations of Cognitive Science</em>, Cambridge, MA: MIT
Press.</li>

<li>Franklin-Hall, L. R., 2016, &ldquo;High-Level Explanation and the
Interventionist&rsquo;s &lsquo;Variables Problem&rsquo;&rdquo;,
<em>The British Journal for the Philosophy of Science</em>, 67(2):
553&ndash;577. doi:10.1093/bjps/axu040</li>

<li>Jansson, Lina, &amp; Saatsi, Juha, 2017, &ldquo;Explanatory
abstractions&rdquo;,&nbsp;<em>The British Journal for the Philosophy
of Science</em>, 70(3): 817&ndash;844. doi:10.1093/bjps/axx016</li>

<li>Glennan, Stuart S., 1996, &ldquo;Mechanisms and the Nature of
Causation&rdquo;, <em>Erkenntnis</em>, 44(1): 49&ndash;71.
doi:10.1007/BF00172853</li>

<li>&ndash;&ndash;&ndash;, 1997, &ldquo;Capacities, Universality, and
Singularity&rdquo;, <em>Philosophy of Science</em>, 64(4):
605&ndash;626. doi:10.1086/392574</li>

<li>&ndash;&ndash;&ndash;, 2017, <em>The New Mechanical
Philosophy</em>, Oxford: Oxford University Press.
doi:10.1093/oso/9780198779711.001.0001</li>

<li>Glymour, Clark, 1980, &ldquo;Explanations, Tests, Unity and
Necessity&rdquo;, <em>No&ucirc;s</em>, 14(1): 31&ndash;50.
doi:10.2307/2214888</li>

<li>Halina, Marta, 2018, &ldquo;Mechanistic Explanation and Its
Limits&rdquo;, in <em>The Routledge Handbook of Mechanisms and
Mechanical Philosophy</em>, Stuart Glennan and Phyllis Illari (eds.),
New York: Routledge, 213&ndash;224.</li>

<li>Hall, Ned, 2012, &ldquo;Comments on Michael Strevens&rsquo;s
<em>Depth</em>&rdquo;, <em>Philosophy and Phenomenological
Research</em>, 84(2): 474&ndash;482.
doi:10.1111/j.1933-1592.2011.00575.x</li>

<li>[EG2] Hitchcock, Christopher and James Woodward, 2003,
&ldquo;Explanatory Generalizations, Part II: Plumbing Explanatory
Depth&rdquo;, <em>No&ucirc;s</em>, 37(2): 181&ndash;199. [For EG1, see
Woodward &amp; Hitchcock 2003.] doi:10.1111/1468-0068.00435</li>

<li>Huneman, Philippe, 2010, &ldquo;Topological Explanations and
Robustness in Biological Sciences&rdquo;, <em>Synthese</em>, 177(2):
213&ndash;245. doi:10.1007/s11229-010-9842-z</li>

<li>Illari, Phyllis McKay and Jon Williamson, 2010, &ldquo;Function
and Organization: Comparing the Mechanisms of Protein Synthesis and
Natural Selection&rdquo;, <em>Studies in History and Philosophy of
Science Part C: Studies in History and Philosophy of Biological and
Biomedical Sciences</em>, 41(3): 279&ndash;291.
doi:10.1016/j.shpsc.2010.07.001</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;What Is a Mechanism? Thinking
about Mechanisms across the Sciences&rdquo;, <em>European Journal for
Philosophy of Science</em>, 2(1): 119&ndash;135.
doi:10.1007/s13194-011-0038-2</li>

<li>Kosti&#263;, Daniel, 2020, &ldquo;General Theory of Topological
Explanations and Explanatory Asymmetry&rdquo;, <em>Philosophical
Transactions of the Royal Society B: Biological Sciences</em>,
375(1796): 20190321. doi:10.1098/rstb.2019.0321</li>

<li>Kaplan, David Michael and Carl F. Craver, 2011, &ldquo;The
Explanatory Force of Dynamical and Mathematical Models in
Neuroscience: A Mechanistic Perspective&rdquo;, <em>Philosophy of
Science</em>, 78(4): 601&ndash;627. doi:10.1086/661755</li>

<li>Lange, Marc, 2013, &ldquo;What Makes a Scientific Explanation
Distinctively Mathematical?&rdquo;, <em>The British Journal for the
Philosophy of Science</em>, 64(3): 485&ndash;511.
doi:10.1093/bjps/axs012</li>

<li>&ndash;&ndash;&ndash;, 2016, <em>Because without Cause: Non-Causal
Explanations in Science and Mathematics</em>, (Oxford Studies in
Philosophy of Science), New York: Oxford University Press.
doi:10.1093/acprof:oso/9780190269487.001.0001</li>

<li>Levy, Arnon, 2014, &ldquo;What Was Hodgkin and Huxley&rsquo;s
Achievement?&rdquo;, <em>The British Journal for the Philosophy of
Science</em>, 65(3): 469&ndash;492. doi:10.1093/bjps/axs043</li>

<li>Levy, Arnon and William Bechtel, 2013, &ldquo;Abstraction and the
Organization of Mechanisms&rdquo;, <em>Philosophy of Science</em>,
80(2): 241&ndash;261. doi:10.1086/670300</li>

<li>Lyon, Aidan, 2012, &ldquo;Mathematical Explanations Of Empirical
Facts, And Mathematical Realism&rdquo;, <em>Australasian Journal of
Philosophy</em>, 90(3): 559&ndash;578.
doi:10.1080/00048402.2011.596216</li>

<li>Lyon, Aidan and Mark Colyvan, 2008, &ldquo;The Explanatory Power
of Phase Spaces&rdquo;, <em>Philosophia Mathematica</em>, 16(2):
227&ndash;243. doi:10.1093/philmat/nkm025</li>

<li>Machamer, Peter, 2004, &ldquo;Activities and Causation: The
Metaphysics and Epistemology of Mechanisms&rdquo;, <em>International
Studies in the Philosophy of Science</em>, 18(1): 27&ndash;39.
doi:10.1080/02698590412331289242</li>

<li>[MDC] Machamer, Peter, Lindley Darden, and Carl F. Craver, 2000,
&ldquo;Thinking about Mechanisms&rdquo;, <em>Philosophy of
Science</em>, 67(1): 1&ndash;25. doi:10.1086/392759</li>

<li>Mackie, J. L., 1974, <em>The Cement of the Universe: A Study of
Causation</em>, (The Clarendon Library of Logic and Philosophy),
Oxford: Clarendon Press. doi:10.1093/0198246420.001.0001</li>

<li>Morgan, Stephen L. and Christopher Winship, 2014,
<em>Counterfactuals and Causal Inference: Methods and Principles for
Social Research</em>, second edition, (Analytical Methods for Social
Research), New York, NY: Cambridge University Press.
doi:10.1017/CBO9781107587991</li>

<li>Ney, Alyssa, 2009, &ldquo;Physical Causation and
Difference-Making&rdquo;, <em>The British Journal for the Philosophy
of Science</em>, 60(4): 737&ndash;764. doi:10.1093/bjps/axp037</li>

<li>&ndash;&ndash;&ndash;, 2016, &ldquo;Microphysical Causation and
the Case for Physicalism&rdquo;, <em>Analytic Philosophy</em>, 57(2):
141&ndash;164. doi:10.1111/phib.12082</li>

<li>Pearl, Judea, 2000 [2009], <em>Causality: Models, Reasoning, and
Inference</em>, Cambridge: Cambridge University Press. Second edition
2009. doi:10.1017/CBO9780511803161</li>

<li>Piccinini, Gualtiero, 2006, &ldquo;Computational Explanation in
Neuroscience&rdquo;, <em>Synthese</em>, 153(3): 343&ndash;353.
doi:10.1007/s11229-006-9096-y</li>

<li>Piccinini, Gualtiero and Carl Craver, 2011, &ldquo;Integrating
Psychology and Neuroscience: Functional Analyses as Mechanism
Sketches&rdquo;, <em>Synthese</em>, 183(3): 283&ndash;311.
doi:10.1007/s11229-011-9898-4</li>

<li>Potochnik, Angela, 2011, &ldquo;Explanation and Understanding: An
Alternative to Strevens&rsquo; Depth&rdquo;, <em>European Journal for
Philosophy of Science</em>, 1(1): 29&ndash;38.
doi:10.1007/s13194-010-0002-6</li>

<li>&ndash;&ndash;&ndash;, 2015, &ldquo;Causal patterns and adequate
explanations&rdquo;, <em>Philosophical Studies</em>, 172:
1163&ndash;1182. doi:10.1007/s11098-014-0342-8</li>

<li>&ndash;&ndash;&ndash;, 2017, <em>Idealization and the Aims of
Science</em>, Chicago, IL: University of Chicago Press.</li>

<li>Pincock, Christopher, 2007, &ldquo;A Role for Mathematics in the
Physical Sciences&rdquo;, <em>No&ucirc;s</em>, 41(2): 253&ndash;275.
doi:10.1111/j.1468-0068.2007.00646.x</li>

<li>&ndash;&ndash;&ndash;, 2012, <em>Mathematics and Scientific
Representation</em>, (Oxford Studies in Philosophy of Science),
Oxford/New York: Oxford University Press.
doi:10.1093/acprof:oso/9780199757107.001.0001</li>

<li>&ndash;&ndash;&ndash;, 2022, &ldquo;Concrete Scale Models,
Essential Idealization, and Causal Explanation<em>&rdquo;, The British
Journal for the Philosophy of Science</em>, 73(2):
299&ndash;323. doi:10.1093/bjps/axz019</li>

<li>Rathkopf, Charles, 2018, &ldquo;Network Representation and Complex
Systems&rdquo;, <em>Synthese</em>, 195(1): 55&ndash;78.
doi:10.1007/s11229-015-0726-0</li>

<li>Rescorla, Michael, 2014, &ldquo;The Causal Relevance of Content to
Computation&rdquo;, <em>Philosophy and Phenomenological Research</em>,
88(1): 173&ndash;208. doi:10.1111/j.1933-1592.2012.00619.x</li>

<li>Reutlinger, Alexander, 2014, &ldquo;Why Is There Universal
Macrobehavior? Renormalization Group Explanation as Noncausal
Explanation&rdquo;, <em>Philosophy of Science</em>, 81(5):
1157&ndash;1170. doi:10.1086/677887</li>

<li>Reutlinger,&nbsp;Alexander and Andersen, Holly, 2016,
&ldquo;Abstract versus Causal Explanations?&rdquo;, <em>International
Studies in the Philosophy of Science</em>, 30(2):
129&ndash;146. doi:10.1080/02698595.2016.1265867</li>

<li>Reutlinger, Alexander and&nbsp;Saatsi,&nbsp;Juha (eds.), 2018,
<em>Explanation beyond Causation: Philosophical Perspectives on
Non-Causal Explanations</em>, Oxford: Oxford University Press.
doi:10.1093/oso/9780198777946.001.0001</li>

<li>Rice, Collin, 2021, <em>Leveraging Distortions: Explanation,
Idealization, and Universality in Science</em>, Cambridge, MA: The MIT
Press.</li>

<li>Ross, Lauren N., 2015, &ldquo;Dynamical Models and Explanation in
Neuroscience&rdquo;, <em>Philosophy of Science</em>, 82(1):
32&ndash;54. doi:10.1086/679038</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;Causal Selection and the
Pathway Concept&rdquo;, <em>Philosophy of Science</em>, 85(4):
551&ndash;572. doi:10.1086/699022</li>

<li>&ndash;&ndash;&ndash;, 2020, &ldquo;Multiple Realizability from a
Causal Perspective&rdquo;, <em>Philosophy of Science</em>, 87(4):
640&ndash;662. doi:10.1086/709732</li>

<li>&ndash;&ndash;&ndash;, 2021a, &ldquo;Causal Concepts in Biology:
How Pathways Differ from Mechanisms and Why It Matters&rdquo;, <em>The
British Journal for the Philosophy of Science</em>, 72(1):
131&ndash;158. doi:10.1093/bjps/axy078</li>

<li>&ndash;&ndash;&ndash;, 2021b, &ldquo;Distinguishing Topological
and Causal Explanation&rdquo;, <em>Synthese</em>, 198(10):
9803&ndash;9820. doi:10.1007/s11229-020-02685-1</li>

<li>&ndash;&ndash;&ndash;, forthcoming, &ldquo;Cascade versus
Mechanism: The Diversity of Causal Structure in Science&rdquo;,
<em>The British Journal for the Philosophy of Science</em>, first
online: 5 December 2022. doi:10.1086/723623</li>

<li>Ross, Lauren N. and James F. Woodward, 2022, &ldquo;Irreversible
(One-Hit) and Reversible (Sustaining) Causation&rdquo;, <em>Philosophy
of Science</em>, 89(5): 889&ndash;898. doi:10.1017/psa.2022.70</li>

<li>Salmon, Wesley C., 1971a, &ldquo;Statistical Explanation&rdquo;,
in Salmon 1971b: 29&ndash;87.</li>

<li>&ndash;&ndash;&ndash; (ed.), 1971b, <em>Statistical Explanation
and Statistical Relevance</em>, Pittsburgh, PA: University of
Pittsburgh Press.</li>

<li>&ndash;&ndash;&ndash;, 1984, <em>Scientific Explanation and the
Causal Structure of the World</em>, Princeton, NJ: Princeton
University Press.</li>

<li>Silberstein, Michael and Anthony Chemero, 2013, &ldquo;Constraints
on Localization and Decomposition as Explanatory Strategies in the
Biological Sciences&rdquo;, <em>Philosophy of Science</em>, 80(5):
958&ndash;970. doi:10.1086/674533</li>

<li>Skow, Bradford, 2014, &ldquo;Are There Non-Causal Explanations (of
Particular Events)?&rdquo;, <em>The British Journal for the Philosophy
of Science</em>, 65(3): 445&ndash;467. doi:10.1093/bjps/axs047</li>

<li>Strevens, Michael, 2008, <em>Depth: An Account of Scientific
Explanation</em>, Cambridge, MA: Harvard University Press.</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;The Causal and Unification
Approaches to Explanation Unified: Causally&rdquo;,
<em>No&ucirc;s</em>, 38(1): 154&ndash;176.
doi:10.1111/j.1468-0068.2004.00466.x</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;Causality Reunified&rdquo;,
<em>Erkenntnis</em>, 78(S2): 299&ndash;320.
doi:10.1007/s10670-013-9514-8</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;The Mathematical Route to
Causal Understanding&rdquo;, in Reutlinger and Saatsi 2018:
117&ndash;140 (ch. 5).</li>

<li>Sober, Elliott, 1983, &ldquo;Equilibrium
Explanation&rdquo;, <em>Philosophical Studies: An International
Journal for Philosophy in the Analytic Tradition</em>, 43(2):
201&ndash;10.</li>

<li>&ndash;&ndash;&ndash;,&nbsp;1999, &ldquo;The Multiple
Realizability Argument against Reductionism&rdquo;, <em>Philosophy of
Science</em>, 66(4): 542&ndash;564. doi:10.1086/392754</li>

<li>Waters, C. Kenneth, 1990, &ldquo;Why the Anti-Reductionist
Consensus Won&rsquo;t Survive the Case of Classical Mendelian
Genetics&rdquo;, <em>PSA: Proceedings of the Biennial Meeting of the
Philosophy of Science Association</em>, 1990(1): 125&ndash;139.
doi:10.1086/psaprocbienmeetp.1990.1.192698</li>

<li>Weslake, Brad, 2010, &ldquo;Explanatory Depth&rdquo;,
<em>Philosophy of Science</em>, 77(2): 273&ndash;294.
doi:10.1086/651316</li>

<li>Wigner, Eugene Paul, 1967, <em>Symmetries and Reflections:
Scientific Essays of Eugene P. Wigner</em>, Bloomington, IN: Indiana
University Press.</li>

<li>Woodward, James, 2002, &ldquo;What Is a Mechanism? A
Counterfactual Account&rdquo;, <em>Philosophy of Science</em>, 69(S3):
S366&ndash;S377. doi:10.1086/341859</li>

<li>&ndash;&ndash;&ndash;, 2003, <em>Making Things Happen: A Theory of
Causal Explanation</em>, Oxford/New York: Oxford University Press.
doi:10.1093/0195155270.001.0001</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Sensitive and Insensitive
Causation&rdquo;, <em>The Philosophical Review</em>, 115(1):
1&ndash;50. doi:10.1215/00318108-2005-001.</li>

<li>&ndash;&ndash;&ndash;, 2010, &ldquo;Causation in Biology:
Stability, Specificity, and the Choice of Levels of
Explanation&rdquo;, <em>Biology &amp; Philosophy</em>, 25(3):
287&ndash;318. doi:10.1007/s10539-010-9200-z</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;Mechanistic Explanation: Its
Scope and Limits&rdquo;, <em>Aristotelian Society Supplementary
Volume</em>, 87: 39&ndash;65.
doi:10.1111/j.1467-8349.2013.00219.x</li>

<li>&ndash;&ndash;&ndash;, 2017a, &ldquo;Explanation in Neurobiology:
An Interventionist Perspective&rdquo;, in <em>Explanation and
Integration in Mind and Brain Science</em>, David M. Kaplan (ed.),
Oxford: Oxford University Press, ch. 5.</li>

<li>&ndash;&ndash;&ndash;, 2017b, &ldquo;Interventionism and the
Missing Metaphysics: A Dialogue&rdquo;, in <em>Metaphysics and the
Philosophy of Science: New Essays</em>, Matthew Slater and Zanja
Yudell (eds.), New York: Oxford University Press, 193&ndash;228.
doi:10.1093/acprof:oso/9780199363209.003.0010</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;Some Varieties of Non-Causal
Explanation&rdquo;, in Reutlinger and Saatsi 2018: 117&ndash;140.</li>

<li>&ndash;&ndash;&ndash;, 2020, &ldquo;Causal Complexity, Conditional
Independence, and Downward Causation&rdquo;, <em>Philosophy of
Science</em>, 87(5): 857&ndash;867. doi:10.1086/710631</li>

<li>&ndash;&ndash;&ndash;, 2021, &ldquo;Explanatory Autonomy: The Role
of Proportionality, Stability, and Conditional Irrelevance&rdquo;,
<em>Synthese</em>, 198(1): 237&ndash;265.
doi:10.1007/s11229-018-01998-6</li>

<li>[EG1] Woodward, James and Christopher Hitchcock, 2003,
&ldquo;Explanatory Generalizations, Part I: A Counterfactual
Account&rdquo;, <em>No&ucirc;s</em>, 37(1): 1&ndash;24. [For EG2, see
Hitchcock &amp; Woodward 2003.] doi:10.1111/1468-0068.00426</li>
</ul>
</div> 

<div id="academic-tools">
<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=causal-explanation-science" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/causal-explanation-science/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=causal-explanation-science&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/causal-explanation-science/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>

<p>
[Please contact the author with suggestions.]</p>
</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../causal-models/">causal models</a> |
 <a href="../causation-mani/">causation: and manipulability</a> |
 <a href="../causation-regularity/">causation: regularity and inferential theories of</a> |
 <a href="../mathematics-explanation/">mathematical: explanation</a> |
 <a href="../models-science/">models in science</a> |
 <a href="../scientific-explanation/">scientific explanation</a>

</p>
</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
Thanks to Carl Craver, Michael Strevens and an anonymous referee for
helpful comments on a draft of this entry.</p>
</div>
<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2023</a> by

<br />
<a href="https://www.lps.uci.edu/~rossl/" target="other">Lauren Ross</a>
&lt;<a href="m&#97;ilto:rossl&#37;40uci&#37;2eedu"><em>rossl<abbr title=" at ">&#64;</abbr>uci<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;<br />
<a href="https://www.hps.pitt.edu/people/james-woodward" target="other">James Woodward</a>
&lt;<a href="m&#97;ilto:jfw&#37;40pitt&#37;2eedu"><em>jfw<abbr title=" at ">&#64;</abbr>pitt<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../contents.html">Table of Contents</a></li>
            <li role="menuitem"><a href="../../new.html">What's New</a></li>
            <li role="menuitem"><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li role="menuitem"><a href="../../published.html">Chronological</a></li>
            <li role="menuitem"><a href="../../archives/">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../info.html">Editorial Information</a></li>
            <li role="menuitem"><a href="../../about.html">About the SEP</a></li>
            <li role="menuitem"><a href="../../board.html">Editorial Board</a></li>
            <li role="menuitem"><a href="../../cite.html">How to Cite the SEP</a></li>
            <li role="menuitem"><a href="../../special-characters.html">Special Characters</a></li>
            <li role="menuitem"><a href="../../tools/">Advanced Tools</a></li>
            <li role="menuitem"><a href="../../accessibility.html">Accessibility</a></li>
            <li role="menuitem"><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li role="menuitem"><a href="../../support/">Support the SEP</a></li>
            <li role="menuitem"><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li role="menuitem"><a href="../../support/donate.html">Make a Donation</a></li>
            <li role="menuitem"><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2023</a> by <a href="https://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>
</html>
